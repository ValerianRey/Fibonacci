{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-vector product vs Matrix element-wise multiplication by vector (cuda float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "n_in = 9216\n",
    "n_out = 128\n",
    "batch_size = 256\n",
    "W = torch.empty(n_out, n_in).normal_().to(device=device)\n",
    "x = torch.linspace(-10, 10, n_in).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 349.95646ms\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "result_1 = W @ x\n",
    "elapsed_time = time.clock() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.5f}\".format(elapsed_time * 1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.75991ms\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "result_2 = W * x\n",
    "elapsed_time = time.clock() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.5}\".format(elapsed_time * 1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-vector product vs Matrix element-wise multiplication by vector (cpu int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "n_in = 9216\n",
    "n_out = 128\n",
    "batch_size = 256\n",
    "W = torch.empty(n_out, n_in, dtype=torch.int8).random_(-128, 127).to(device=device)\n",
    "x = torch.empty(n_in, dtype=torch.int8).random_(-128, 127).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.10611ms\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "result_1 = W @ x\n",
    "elapsed_time = time.clock() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.5f}\".format(elapsed_time * 1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.4961ms\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "result_2 = (W * x)\n",
    "elapsed_time = time.clock() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.5}\".format(elapsed_time * 1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer VS manual matrix vector product VS element-wise multiplication + sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "fc = nn.Linear(n_in, n_out, bias=False).to(device=device)\n",
    "for parameter in fc.parameters():\n",
    "    parameter.requires_grad = False  # This increases the speed of result 4 like CRAZY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor(batch_size, n_in).normal_().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.016s - Time per iteration: 0.160ms\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "start = time.clock()\n",
    "for i in range(n_iter):\n",
    "    results = fc(inputs)\n",
    "elapsed_time = time.clock() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.3f}\".format(elapsed_time) + \"s - Time per iteration: \" + \"{0:0.3f}\".format(elapsed_time/n_iter*1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.082s - Time per iteration: 0.816ms\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "W = fc.weight.data\n",
    "start = time.time()\n",
    "for i in range(n_iter):\n",
    "    result = W @ inputs.view(n_in, -1)\n",
    "    torch.cuda.synchronize()\n",
    "elapsed_time = time.time() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.3f}\".format(elapsed_time) + \"s - Time per iteration: \" + \"{0:0.3f}\".format(elapsed_time/n_iter*1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.674s - Time per iteration: 36.742ms\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "W = fc.weight.data\n",
    "start = time.time()\n",
    "for i in range(n_iter):\n",
    "    inputs_expanded = inputs.unsqueeze(1).expand(batch_size, n_out, n_in)\n",
    "    result = (W * inputs_expanded).sum(axis=2)\n",
    "    torch.cuda.synchronize()\n",
    "elapsed_time = time.time() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.3f}\".format(elapsed_time) + \"s - Time per iteration: \" + \"{0:0.3f}\".format(elapsed_time/n_iter*1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the signs matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "W = torch.empty(n_out, n_in, dtype=torch.int8).random_(-128, 127).to(device)\n",
    "input_ = torch.empty(n_in, dtype=torch.int8).random_(-128, 127).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -51,  112, -110,  ..., -103,   12,   -1],\n",
       "        [ -80,  119,   43,  ...,  119,  109,  -25],\n",
       "        [-124,  112,  -52,  ...,  -14,  -46,   10],\n",
       "        ...,\n",
       "        [ -12,  -29,   66,  ...,   90,  -92,   49],\n",
       "        [  -8,  -35,   58,  ...,  107,   83,  118],\n",
       "        [ 117, -100,   66,  ...,   42,   55,  111]], device='cuda:0',\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-118,  -36,   37,  ...,   97, -111,   71], device='cuda:0',\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, -1, -1,  ..., -1, -1, -1],\n",
       "        [ 1, -1,  1,  ...,  1, -1, -1],\n",
       "        [ 1, -1, -1,  ..., -1,  1,  1],\n",
       "        ...,\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 1,  1,  1,  ...,  1, -1,  1],\n",
       "        [-1,  1,  1,  ...,  1, -1,  1]], device='cuda:0', dtype=torch.int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_signs = torch.sign(W)  # The weight signs are precomputed (out of time benchmark)\n",
    "input_signs = torch.sign(input_)\n",
    "w_signs * input_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.326s - Time per iteration: 0.3262ms\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1000\n",
    "start = time.time()\n",
    "if device == torch.device(\"cuda\"):\n",
    "    for i in range(n_iter):\n",
    "        input_signs = torch.sign(input_)  # A bit slower with cpu, a bit faster with cuda\n",
    "        signs_matrix = w_signs * input_signs\n",
    "else:\n",
    "    for i in range(n_iter):\n",
    "        input_signs = ((input_ >> 7) * -2 + 1)\n",
    "        signs_matrix = w_signs * input_signs\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.3f}\".format(elapsed_time) + \"s - Time per iteration: \" + \"{0:0.4f}\".format(elapsed_time/n_iter * 1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the absolute value of the tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the absolute value of the smallest number is bugged because it doesnt exist in that dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute value of int8 -127 is 127\n",
      "Absolute value of int8 -128 is -128\n"
     ]
    }
   ],
   "source": [
    "value1 = torch.abs(torch.tensor(-127, dtype=torch.int8)).item()\n",
    "value2 = torch.abs(torch.tensor(-128, dtype=torch.int8)).item()\n",
    "print(\"Absolute value of int8 -127 is \" + repr(value1))\n",
    "print(\"Absolute value of int8 -128 is \" + repr(value2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "W = torch.empty(n_out, n_in, dtype=torch.int8).random_(-127, 127).to(device)  # We only range from -127 to avoid bug of abs\n",
    "input_ = torch.empty(n_in, dtype=torch.int8).random_(-127, 127).to(device)  # Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_W = torch.abs(W)  # This can be precomputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.188s - Time per iteration: 0.0188ms\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10000\n",
    "start = time.time()\n",
    "for i in range(n_iter):\n",
    "    torch.abs(input_)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"Elapsed time: \" + \"{0:0.3f}\".format(elapsed_time) + \"s - Time per iteration: \" + \"{0:0.4f}\".format(elapsed_time/n_iter*1000) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_in = 9216\n",
    "n_out = 128\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Generate W and precompute it's element-wise signs and absolute values\n",
    "W = torch.empty(n_out, n_in, dtype=torch.int8, device=device).random_(-127, 127)\n",
    "abs_W = torch.abs(W)\n",
    "signs_W = torch.sign(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch_size inputs\n",
    "inputs = torch.empty(batch_size, n_in, dtype=torch.int8, device=device).random_(-127, 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_inputs_expanded = torch.abs(inputs).unsqueeze(1).expand(batch_size, n_out, n_in)\n",
    "signs_inputs_expanded = torch.sign(inputs).unsqueeze(1).expand(batch_size, n_out, n_in)\n",
    "signs_matrices = signs_W * signs_inputs_expanded\n",
    "\n",
    "# The first multiplication (abs_W * abs_inputs_expanded) can use only fib encoded numbers\n",
    "# The second multiplication (... * signs_matrices) is always an unsigned int * a sign\n",
    "result = torch.zeros_like(abs_W, dtype=torch.int32)\n",
    "torch.mul(abs_W, abs_inputs_expanded, out=result)\n",
    "torch.mul(result, signs_matrices, out=result)\n",
    "result = result.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  124919,    17463,   719267,  ...,   659946,   311491,  -123796],\n",
       "        [   63963,    52231,   254040,  ...,   109001,  -336216,   527265],\n",
       "        [ -305826,  -184486,  -226610,  ...,   391587,   436289,   677266],\n",
       "        ...,\n",
       "        [   14338,  -401019,  1186352,  ...,   799077,  -169431,   324332],\n",
       "        [  350296,  -412467,   267032,  ...,   684719,  -822997,   176550],\n",
       "        [-1360311,   -43620,  -216654,  ...,   142338,  -946051,   261857]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "inputs_cuda = inputs.to(dtype=torch.float32, device=device)\n",
    "fc = nn.Linear(n_in, n_out, bias=False).to(device=device)\n",
    "with torch.no_grad():\n",
    "    fc.weight.data = W.to(dtype=torch.float32, device=device)\n",
    "    result_baseline = fc(inputs_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  124919.,    17463.,   719267.,  ...,   659946.,   311491.,\n",
       "          -123796.],\n",
       "        [   63963.,    52231.,   254040.,  ...,   109001.,  -336216.,\n",
       "           527265.],\n",
       "        [ -305826.,  -184486.,  -226610.,  ...,   391587.,   436289.,\n",
       "           677266.],\n",
       "        ...,\n",
       "        [   14338.,  -401019.,  1186352.,  ...,   799077.,  -169431.,\n",
       "           324332.],\n",
       "        [  350296.,  -412467.,   267032.,  ...,   684719.,  -822997.,\n",
       "           176550.],\n",
       "        [-1360311.,   -43620.,  -216654.,  ...,   142338.,  -946051.,\n",
       "           261857.]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check equality between baseline and positive matrix product trick\n",
    "torch.all(torch.eq(result.to(dtype=torch.float32, device=device), result_baseline)).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
